{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aad01e2",
   "metadata": {},
   "source": [
    "# Tarea 1 - MEL\n",
    "\n",
    "Alejandro Mantilla - 201711304\n",
    "\n",
    "Ximena Palacio - 201730995\n",
    "\n",
    "Juan Manuel Betancourt - 201632544"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a75fb",
   "metadata": {},
   "source": [
    "## Parte A. Problemas Teóricos y Conceptuales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8c825",
   "metadata": {},
   "source": [
    "### Problema 1. Fundamentos de Inferencia Paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895cd6d",
   "metadata": {},
   "source": [
    "Ayuda:\n",
    "* Si $Z \\sim \\text{Normal}(0, 1)$, entonces $Z^{2}\\sim \\chi^{2}(1)$.\n",
    "* Si $Z_{1} \\sim \\chi^{2}(v_{1})$ y $Z_{2} \\sim \\chi^{2}(v_{2})$ y  $Z_{1}$ y $Z_{2}$ son independientes, entonces $(Z_{1} + Z_{2}) \\sim\\chi^{2}(v_{1} + v_{2})$.\n",
    "* $\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2}$ y $\\bar{Y}$ son independientes en el caso de $Y_{i} \\sim \\text{Normal}(\\mu,\\sigma^{2})$.\n",
    "\n",
    "Se tiene una muestra aleatoria $Y_1, Y_2, \\cdots , Y_n$ de una población $Y \\sim \\text{Normal}(0, 1)$. Demuestre:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e9468",
   "metadata": {},
   "source": [
    "__1.__ $\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^{n}Y_{i} \\sim \\text{Normal}(0,1/n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c71a18",
   "metadata": {},
   "source": [
    "Partimos de que\n",
    "\n",
    "$$\n",
    "Y_{i}\\sim \\text{Normal}(0,1).\n",
    "$$\n",
    "\n",
    "Por propiedad de la varianza de la distribución normal, multiplicar la variable por un factor, afecta la distribución de manera que la varianza se multiplica por el cuadrado del factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8698b3",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    \\frac{Y_{i}}{n} &\\sim \\text{Normal}(0,1/{n^{2}})\\\\\n",
    "    \\frac{Y_{1}}{n} + \\frac{Y_{2}}{n} + \\cdots + \\frac{Y_{n}}{n} &\\sim \\text{Normal}(0,\\underbrace{1/n^{2} + 1/n^{2} + \\cdots + 1/n^{2}}_{n \\text{ veces}} )\\\\\n",
    "    \\sum_{i=1}^{n}\\frac{Y_{i}}{n} = \\frac{1}{n}\\sum_{i=1}^{n}Y_{i} &\\sim \\text{Normal}(0,\\sum_{i=1}^{n}1/{n^{2}})\\\\\n",
    "    \\frac{1}{n}\\sum_{i=1}^{n}Y_{i} &\\sim \\text{Normal}(0,\\frac{1}{n}\\sum_{i=1}^{n}1/{n})\\\\\n",
    "    \\frac{1}{n}\\sum_{i=1}^{n}Y_{i} &\\sim \\text{Normal}(0,1/n).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87b203",
   "metadata": {},
   "source": [
    "__2.__ $\\sum_{i=1}^{n}Y_{i}^{2} \\sim \\chi^{2}(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c3f68",
   "metadata": {},
   "source": [
    "Demostraremos por inducción, dadas la primera y segunda ayuda.\n",
    "        \n",
    "__Paso base (__$n = 1$__):__\n",
    "\n",
    "$$\n",
    "    \\sum_{i = 1}^{1}Y_{i}^{2} = Y_{1}^{2} \\sim \\chi^{2}(1)\n",
    "$$\n",
    "\n",
    "La primera ayuda garantiza la afirmación.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4dea9",
   "metadata": {},
   "source": [
    "__Paso inductivo (suponer para__ $n = k$__, demostrar para__ $n = k+1$__):__\n",
    "        \n",
    "Suponemos que\n",
    "$$\n",
    "\\sum_{i=1}^{k}Y_{i}^{2} = Y_{1}^{2} + Y_{2}^{2} + \\cdots + Y_{k-1}^{2} + Y_{k}^{2} \\sim \\chi^{2}(k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c0a30",
   "metadata": {},
   "source": [
    "Ahora debemos demostrar que\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{k+1}Y_{i}^{2} \\sim \\chi^{2}(k+1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0e4c9",
   "metadata": {},
   "source": [
    "Como implicación del supuesto y del paso base, obtenemos que\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{k+1}Y_{i}^{2} = \\underbrace{\\left[Y_{1}^{2} + Y_{2}^{2} + \\cdots + Y_{k-1}^{2} + Y_{k}^{2}\\right]}_{\\sim \\chi^{2}(k)} + \\underbrace{\\left[Y_{k+1}^{2}\\right]}_{\\sim \\chi^{2}(1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c9947",
   "metadata": {},
   "source": [
    "Como implicación de la segunda ayuda, obtenemos que\n",
    "$$\n",
    "\\sum_{i=1}^{k+1}Y_{i}^{2} = \\underbrace{\\left[Y_{1}^{2} + Y_{2}^{2} + \\cdots + Y_{k-1}^{2} + Y_{k}^{2}\\right]}_{\\sim \\chi^{2}(k)} + \\underbrace{\\left[Y_{k+1}^{2}\\right]}_{\\sim \\chi^{2}(1)} \\sim \\chi^{2}((k) + (1)) = \\chi^{2}(k+1).\n",
    "$$\n",
    "        \n",
    "Con esto, hemos demostrado la afirmación inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c8309",
   "metadata": {},
   "source": [
    " __3.__ $\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2} \\sim \\chi^{2}(n-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee377e5",
   "metadata": {},
   "source": [
    "Por propiedad de la distribución normal y la primera ayuda, $\\bar{Y} \\sim \\text{Normal}\\left(0, \\frac{1}{n}\\right) \\Rightarrow \\frac{\\bar{Y}}{1/\\sqrt{n}} \\sim \\text{Normal}(0,1) \\Rightarrow \\left(\\frac{\\bar{Y}}{1/\\sqrt{n}}\\right)^{2} \\sim \\chi^{2}(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca50479",
   "metadata": {},
   "source": [
    "Desarrollemos lo demostrado en el punto anterior, $\\sum_{i=1}^{n}Y_{i}^{2} \\sim \\chi^{2}(n)$.\n",
    "\\begin{align*}\n",
    "    \\sum_{i=1}^{n}Y_{i}^{2} &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y} + \\bar{Y}\\right)^{2}\\\\\n",
    "    &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2} + \\sum_{i=1}^{n}\\bar{Y}^{2} + 2\\bar{Y}\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right).\n",
    "\\end{align*}        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2177b5",
   "metadata": {},
   "source": [
    "Por propiedad de la muestra de la media, podemos ver que $\\sum_{i=1}^{n}Y_{i} = n\\bar{Y}$, por lo cual $\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right) = n\\bar{Y}-n\\bar{Y} = 0$.\n",
    "        \n",
    "Seguimos con el desarrollo:\n",
    "\\begin{align*}\n",
    "    \\sum_{i=1}^{n}Y_{i}^{2} &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2} + \\sum_{i=1}^{n}\\bar{Y}^{2} + \\underbrace{2\\bar{Y}\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)}_{=0}\\\\\n",
    "    &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2} + \\sum_{i=1}^{n}\\bar{Y}^{2}\\\\\n",
    "    &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2} + n\\bar{Y}^{2}\\\\\n",
    "    &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2} + \\underbrace{\\left(\\frac{\\bar{Y}}{1/\\sqrt{n}}\\right)^{2}}_{\\sim \\chi^{2}(1)}.\n",
    "\\end{align*}        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc4e95",
   "metadata": {},
   "source": [
    "Ahora despejamos para la suma original cuya distribución queremos conocer y aplicamos la indicación de la segunda ayuda.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\underbrace{\\sum_{i=1}^{n}Y_{i}^{2}}_{\\sim \\chi^{2}(n)} - \\underbrace{\\left(\\frac{\\bar{Y}}{1/\\sqrt{n}}\\right)^{2}}_{\\sim \\chi^{2}(1)} &= \\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2}\\\\\n",
    "    \\underbrace{\\sum_{i=1}^{n}Y_{i}^{2}}_{\\sim \\chi^{2}(n)} - \\underbrace{\\left(\\frac{\\bar{Y}}{1/\\sqrt{n}}\\right)^{2}}_{\\sim \\chi^{2}(1)} &= \\underbrace{\\sum_{i=1}^{n}\\left(Y_{i} - \\bar{Y}\\right)^{2}}_{\\sim \\chi^{2}(n-1)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ebcdf",
   "metadata": {},
   "source": [
    "__4.__ $c \\cdot \\frac{n\\bar{Y}^{2}}{\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2}} \\sim F(1, n-1)$; con $c = ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2df52",
   "metadata": {},
   "source": [
    "Partimos de la estructura de las variables aleatorias cuya distribución es $F(j, k)$.\n",
    "        \n",
    "Sean $W_{1}$ y $W_{2}$ variables aleatorias con distribución $\\chi^{2}$ con grados de libertad $j$ y $k$ respectivamente. Entonces,\n",
    "\n",
    "$$\n",
    "    \\frac{W_{1} / j}{W_{2} / k} \\sim F(j, k).\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd4b10",
   "metadata": {},
   "source": [
    "Sabemos de demostraciones anteriores que\n",
    "\\begin{align*}\n",
    "    n\\bar{Y}^{2} = \\left(\\frac{\\bar{Y}}{1/\\sqrt{n}}\\right)^{2} &\\sim \\chi^{2}(1)\\text{, y que}\\\\\n",
    "    \\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2} &\\sim \\chi^{2}(n-1).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb58145",
   "metadata": {},
   "source": [
    "Haciendo uso de la tercera ayuda, debido a que el numerador y el denominador son independientes, podemos afirmar la siguiente relación:\n",
    "$$\n",
    "    \\frac{n\\bar{Y}^{2} / 1}{\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2} / (n-1)} \\sim F(1, n-1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc2a76",
   "metadata": {},
   "source": [
    "Concluimos que\n",
    "$$\n",
    "    (n-1)\\cdot \\frac{n\\bar{Y}^{2}}{\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2}} \\sim F(1, n-1)\n",
    "$$\n",
    "y por lo tanto $c=n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff15bb",
   "metadata": {},
   "source": [
    "### Problema 2. Fundamentos Distribuciones Multivariadas: Propiedades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188040ab",
   "metadata": {},
   "source": [
    "Queremos demostrar que la matriz de covarianzas $Cov(\\hat{Y}, Y-\\hat{Y})$ contiene ceros únicamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b07ff2",
   "metadata": {},
   "source": [
    "Sabemos que la expresión matricial para la estimación de $Y$, es la siguiente:\n",
    "$$\n",
    "    \\hat{Y} = X\\left(X'X\\right)^{-1}X'Y = HY.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f88661",
   "metadata": {},
   "source": [
    "Podemos expresar $Y-\\hat{Y}$ como\n",
    "\\begin{align*}\n",
    "    Y-\\hat{Y} &= Y-HY\\\\\n",
    "              &= \\left(I - H\\right)Y.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81860a",
   "metadata": {},
   "source": [
    "Utilizamos la ayuda del enunciado para expresar la matriz de covarianzas. Note que las matrices $H$ e $I$ son simétricas.\n",
    "\\begin{align*}\n",
    "    Cov(\\hat{Y}, Y-\\hat{Y}) &= \\,Cov(HY,\\left(I - H\\right)Y)\\\\\n",
    "                            &= H\\,Cov(Y,Y)\\left(I - H\\right)'\\\\\n",
    "                            &= H\\,Cov(Y,Y)\\left(I' - H'\\right)\\\\\n",
    "                            &= H\\,Cov(Y,Y)\\left(I - H\\right).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6ca75",
   "metadata": {},
   "source": [
    "El supuesto de que las observaciones son independientes entre sí nos permite que $Cov(Y,Y)=I$.\n",
    "\\begin{align*}\n",
    "    Cov(\\hat{Y}, Y-\\hat{Y}) &= H\\,Cov(Y,Y)\\left(I - H\\right)\\\\\n",
    "                            &= H\\,\\left(I - H\\right)\\\\\n",
    "                            &= H - H^{2}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb92b52",
   "metadata": {},
   "source": [
    "Por la indempotencia de $H$,\n",
    "\\begin{align*}\n",
    "    Cov(\\hat{Y}, Y-\\hat{Y}) &= H-H\\\\\n",
    "                            &= 0.\n",
    "\\end{align*}\n",
    "\n",
    "La matriz de covarianzas contiene solo ceros y por lo tanto $Y$ y $Y-\\hat{Y}$ son independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba05a8",
   "metadata": {},
   "source": [
    "### Problema 3. Fundamentos de Inferencia Paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56f3d6",
   "metadata": {},
   "source": [
    "\n",
    "Se tiene una muestra aleatoria $Y_1$, $Y_2$, $\\cdots$, $Y_n$ de una población $Y \\sim \\text{Normal}(\\mu, \\sigma^{2})$. El estimador convencional de la varianza es:\n",
    "$$\n",
    "    S^{2} = \\frac{\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2}}{n-1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a1911",
   "metadata": {},
   "source": [
    "Sin embargo, el estimador por máxima verosimilitud es $\\hat{\\sigma}^{2}=\\frac{(n-1)S^{2}}{n}$. ¿Cuál de los dos es el mejor estimador? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a7f9c",
   "metadata": {},
   "source": [
    "El estimador convencional de la varianza se puede reescribir de la siguiente forma:\n",
    "\\begin{align*}\n",
    "    S^{2} &= \\frac{\\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)^{2}}{n-1}\\\\\n",
    "          &= %\\frac{1}{n-1}(\\sum_{i=1}^{n}Y_{i}^{2}-n\\bar{Y}^{2}).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b96977",
   "metadata": {},
   "source": [
    "$$ S^{2} = \\frac{1}{n-1} \\sum_{i=1}^{n}\\left(Y_{i}-\\bar{Y}\\right)\\left(Y_{i}-\\bar{Y}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37f371",
   "metadata": {},
   "source": [
    "$$ S^{2} = \\frac{1}{n-1} \\sum_{i=1}^{n}Y_{i} ^{2} + \\bar{Y}^{2} - 2Y_{i}\\bar{Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e7579",
   "metadata": {},
   "source": [
    "$$ S^{2} = \\frac{1}{n-1} (\\sum_{i=1}^{n}Y_{i} ^{2} - 2Y_{i}\\bar{Y}) + n\\bar{Y}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da246d46",
   "metadata": {},
   "source": [
    "En general, podemos expresar el ECM del estimador de un parámetro como:\n",
    "$$\n",
    "    \\text{ECM}(\\hat{\\theta}) = E(\\hat{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35326eac",
   "metadata": {},
   "source": [
    "Ahora bien, al calcular el ECM correspondiente a este estimador, se halla que:\n",
    "\\begin{align*}\n",
    "    ECM(S_{n-1}^{2}) &= %\\frac{1}{n}(\\mu_4-\\frac{n-3}{n-1}\\sigma^{4})\\\\\n",
    "    %&= \\frac{1}{n}(\\gamma_2+\\frac{2n}{n-1})\\sigma^{4}.\n",
    "\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3b36d",
   "metadata": {},
   "source": [
    "### Problema 4. Fundamentos de Inferencia Paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0b4ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e957d9",
   "metadata": {},
   "source": [
    "### Problema 5. Fundamentos del Modelo de Regresión Lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfcabf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0adea1",
   "metadata": {},
   "source": [
    "### Problema 6. Fundamentos de Álgebra para Modelos Lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8594f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0037d3ba",
   "metadata": {},
   "source": [
    "### Problema 7. Fundamentos de Inferencia Paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3610d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b72debb7",
   "metadata": {},
   "source": [
    "### Problema 8. Proyecciones y Distribuciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061688ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c174ac1e",
   "metadata": {},
   "source": [
    "## Parte B. Problemas Aplicados con Datos Reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1367666",
   "metadata": {},
   "source": [
    "### Problema 9. _Carseats Sales Data_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0bbfb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6316f985",
   "metadata": {},
   "source": [
    "### Problema 10. Problema Libre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307eb92",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
